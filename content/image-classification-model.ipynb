{"cells":[{"cell_type":"markdown","metadata":{"id":"8KqherxNfaBQ"},"source":["## **CREATING THE MODEL**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SZ7OGmolMqu4"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","import torchvision.transforms as transforms\n","from torch.utils.data import DataLoader\n","import torch.nn.functional as F"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LgF_1cNyNHhz"},"outputs":[],"source":["# Device configuration\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# Hyperparameters\n","num_epochs = 25\n","batch_size = 128\n","learning_rate = 0.001"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xqEIyIVsNIvm"},"outputs":[],"source":["# Data augmentation and normalization for training\n","train_transform = transforms.Compose([\n","    transforms.RandomHorizontalFlip(),\n","    transforms.RandomCrop(32, padding=4),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n","])\n","\n","# Normalization for validation/test\n","val_transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n","])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1966,"status":"ok","timestamp":1720161837810,"user":{"displayName":"Jaswanth Pederedla","userId":"06036392412146825553"},"user_tz":-330},"id":"5TnLIJTqNNtb","outputId":"c56c65a1-7260-473d-a84a-7408ba9d65b1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Files already downloaded and verified\n","Files already downloaded and verified\n"]}],"source":["# CIFAR-10 dataset\n","train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True,\n","                                             download=True, transform=train_transform)\n","val_dataset = torchvision.datasets.CIFAR10(root='./data', train=False,\n","                                           download=True, transform=val_transform)\n","\n","# Data loaders\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"muwqGXBLNSlA"},"outputs":[],"source":["# Define the model\n","class SimpleCNN(nn.Module):\n","    def __init__(self):\n","        super(SimpleCNN, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n","        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n","        self.pool = nn.MaxPool2d(2, 2)\n","        self.fc1 = nn.Linear(64 * 8 * 8, 512)\n","        self.fc2 = nn.Linear(512, 10)\n","\n","    def forward(self, x):\n","        x = self.pool(F.relu(self.conv1(x)))\n","        x = self.pool(F.relu(self.conv2(x)))\n","        x = x.view(-1, 64 * 8 * 8)\n","        x = F.relu(self.fc1(x))\n","        x = self.fc2(x)\n","        return x\n","\n","model = SimpleCNN().to(device)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dVb_iy5RNbxO"},"outputs":[],"source":["# Loss and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","# Learning rate scheduler\n","scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=5, verbose=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b1Ao9VsmNiBZ"},"outputs":[],"source":["# Function to calculate accuracy\n","def accuracy(outputs, labels):\n","    _, predicted = torch.max(outputs, 1)\n","    correct = (predicted == labels).sum().item()\n","    return correct / labels.size(0)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3385083,"status":"ok","timestamp":1720165222890,"user":{"displayName":"Jaswanth Pederedla","userId":"06036392412146825553"},"user_tz":-330},"id":"FBeEFAB9Nnmx","outputId":"5ecb24ba-f8dc-4119-e134-a71cfd6921c0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch [1/25], Train Loss: 1.5475, Train Acc: 0.4376, Val Loss: 1.2202, Val Acc: 0.5611\n","Epoch [2/25], Train Loss: 1.2087, Train Acc: 0.5678, Val Loss: 0.9970, Val Acc: 0.6410\n","Epoch [3/25], Train Loss: 1.0554, Train Acc: 0.6216, Val Loss: 0.9143, Val Acc: 0.6798\n","Epoch [4/25], Train Loss: 0.9645, Train Acc: 0.6591, Val Loss: 0.8967, Val Acc: 0.6899\n","Epoch [5/25], Train Loss: 0.8933, Train Acc: 0.6858, Val Loss: 0.8062, Val Acc: 0.7190\n","Epoch [6/25], Train Loss: 0.8371, Train Acc: 0.7065, Val Loss: 0.7847, Val Acc: 0.7218\n","Epoch [7/25], Train Loss: 0.7985, Train Acc: 0.7186, Val Loss: 0.7585, Val Acc: 0.7379\n","Epoch [8/25], Train Loss: 0.7628, Train Acc: 0.7332, Val Loss: 0.7342, Val Acc: 0.7461\n","Epoch [9/25], Train Loss: 0.7313, Train Acc: 0.7438, Val Loss: 0.7374, Val Acc: 0.7437\n","Epoch [10/25], Train Loss: 0.7023, Train Acc: 0.7533, Val Loss: 0.7009, Val Acc: 0.7615\n","Epoch [11/25], Train Loss: 0.6846, Train Acc: 0.7618, Val Loss: 0.6814, Val Acc: 0.7630\n","Epoch [12/25], Train Loss: 0.6561, Train Acc: 0.7712, Val Loss: 0.6791, Val Acc: 0.7633\n","Epoch [13/25], Train Loss: 0.6365, Train Acc: 0.7778, Val Loss: 0.6485, Val Acc: 0.7727\n","Epoch [14/25], Train Loss: 0.6217, Train Acc: 0.7823, Val Loss: 0.6516, Val Acc: 0.7783\n","Epoch [15/25], Train Loss: 0.6095, Train Acc: 0.7863, Val Loss: 0.6425, Val Acc: 0.7754\n","Epoch [16/25], Train Loss: 0.5906, Train Acc: 0.7936, Val Loss: 0.6406, Val Acc: 0.7783\n","Epoch [17/25], Train Loss: 0.5821, Train Acc: 0.7963, Val Loss: 0.6324, Val Acc: 0.7850\n","Epoch [18/25], Train Loss: 0.5619, Train Acc: 0.8013, Val Loss: 0.6235, Val Acc: 0.7875\n","Epoch [19/25], Train Loss: 0.5552, Train Acc: 0.8049, Val Loss: 0.6300, Val Acc: 0.7822\n","Epoch [20/25], Train Loss: 0.5381, Train Acc: 0.8103, Val Loss: 0.6299, Val Acc: 0.7848\n","Epoch [21/25], Train Loss: 0.5270, Train Acc: 0.8152, Val Loss: 0.6279, Val Acc: 0.7868\n","Epoch [22/25], Train Loss: 0.5139, Train Acc: 0.8204, Val Loss: 0.6373, Val Acc: 0.7872\n","Epoch [23/25], Train Loss: 0.5079, Train Acc: 0.8223, Val Loss: 0.6115, Val Acc: 0.7963\n","Epoch [24/25], Train Loss: 0.5011, Train Acc: 0.8241, Val Loss: 0.6149, Val Acc: 0.7948\n","Epoch [25/25], Train Loss: 0.4926, Train Acc: 0.8271, Val Loss: 0.6188, Val Acc: 0.7961\n","Finished Training\n"]}],"source":["# Training the model\n","for epoch in range(num_epochs):\n","    model.train()\n","    train_loss = 0.0\n","    train_acc = 0.0\n","    for inputs, labels in train_loader:\n","        inputs, labels = inputs.to(device), labels.to(device)\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        train_loss += loss.item() * inputs.size(0)\n","        train_acc += accuracy(outputs, labels) * inputs.size(0)\n","        # Average loss and accuracy\n","    train_loss = train_loss / len(train_loader.dataset)\n","    train_acc = train_acc / len(train_loader.dataset)\n","\n","    # Validation\n","    model.eval()\n","    val_loss = 0.0\n","    val_acc = 0.0\n","    with torch.no_grad():\n","        for inputs, labels in val_loader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","            val_loss += loss.item() * inputs.size(0)\n","            val_acc += accuracy(outputs, labels) * inputs.size(0)\n","\n","    # Average validation loss and accuracy\n","    val_loss = val_loss / len(val_loader.dataset)\n","    val_acc = val_acc / len(val_loader.dataset)\n","\n","    # Adjust learning rate based on validation accuracy\n","    scheduler.step(val_acc)\n","\n","    # Print training progress\n","    print(f'Epoch [{epoch+1}/{num_epochs}], '\n","          f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, '\n","          f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n","\n","print('Finished Training')"]},{"cell_type":"markdown","metadata":{"id":"u9AuYQkUfk6b"},"source":["## **TESTING THE MODEL ON A SAMPLE IMAGE**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tz-OoCA_89Sl"},"outputs":[],"source":["# Load the image\n","from PIL import Image\n","img_path = \"/content/image.jpg\"\n","image = Image.open(img_path)"]},{"cell_type":"markdown","metadata":{"id":"4Jk7YL5Sp_n1"},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1720165222891,"user":{"displayName":"Jaswanth Pederedla","userId":"06036392412146825553"},"user_tz":-330},"id":"plELLMVHNovE","outputId":"eff80bca-70e9-4ca8-850c-db08e7ce3388"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([3, 32, 32])\n"]}],"source":["transform = transforms.Compose([\n","    transforms.Resize((32, 32)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010])  # Example normalization\n","])\n","\n","# Apply the transformation\n","normalized_tensor_image = transform(image)\n","\n","# Verify the size of the normalized tensor\n","print(normalized_tensor_image.size())  # Should print torch.Size([3, 32, 32])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1720165222891,"user":{"displayName":"Jaswanth Pederedla","userId":"06036392412146825553"},"user_tz":-330},"id":"UgQ00nfzYvXR","outputId":"708a4d41-c627-4fc2-ebbc-15c766109478"},"outputs":[{"name":"stdout","output_type":"stream","text":["Predicted class: cat\n"]}],"source":["model.eval()\n","classes = ('plane', 'car', 'bird', 'cat',\n","           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n","with torch.no_grad():\n","    op = model(normalized_tensor_image)\n","    _, predicted = torch.max(op, 1)\n","\n","# Print the predicted class\n","print(f'Predicted class: {classes[predicted.item()]}')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1720165222891,"user":{"displayName":"Jaswanth Pederedla","userId":"06036392412146825553"},"user_tz":-330},"id":"NrGiCcYIZCJq","outputId":"ca6b6af5-b457-43b3-d400-189f0152dfb6"},"outputs":[{"name":"stdout","output_type":"stream","text":[" plane: 0.0009\n"," car: 0.0026\n"," bird: 0.0003\n"," cat: 0.8720\n"," deer: 0.0001\n"," dog: 0.0183\n"," frog: 0.0001\n"," horse: 0.0750\n"," ship: 0.0016\n"," truck: 0.0292\n"]}],"source":["# Classify the image and get probabilities\n","with torch.no_grad():\n","    outputs = model(normalized_tensor_image)\n","    probabilities = F.softmax(outputs, dim=1)  # Apply softmax to get probabilities\n","\n","# Print the probabilities for each class\n","probabilities = probabilities.cpu().numpy().flatten()  # Move to CPU and flatten the tensor\n","for i, prob in enumerate(probabilities):\n","    print(f' {classes[i]}: {prob:.4f}')"]},{"cell_type":"markdown","source":["## **app.py**"],"metadata":{"id":"vYWWCeELRBzz"}},{"cell_type":"code","source":["%%writefile app.py\n","import streamlit as st\n","from PIL import Image\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision.transforms as transforms\n","\n","# Ensure you have the correct device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Define the model\n","class SimpleCNN(torch.nn.Module):\n","    def __init__(self):\n","        super(SimpleCNN, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n","        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n","        self.pool = nn.MaxPool2d(2, 2)\n","        self.fc1 = nn.Linear(64 * 8 * 8, 512)\n","        self.fc2 = nn.Linear(512, 10)\n","\n","    def forward(self, x):\n","        x = self.pool(F.relu(self.conv1(x)))\n","        x = self.pool(F.relu(self.conv2(x)))\n","        x = x.view(-1, 64 * 8 * 8)\n","        x = F.relu(self.fc1(x))\n","        x = self.fc2(x)\n","        return x\n","\n","# Load the trained model weights\n","model = SimpleCNN().to(device)\n","model.load_state_dict(torch.load('cifar10_model.pth', map_location=device))\n","model.eval()\n","\n","# Define the image transformation\n","transform = transforms.Compose([\n","    transforms.Resize((32, 32)),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","])\n","\n","# Define the classes\n","classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n","\n","def predict(image):\n","    image = transform(image).unsqueeze(0).to(device)\n","    with torch.no_grad():\n","        outputs = model(image)\n","        _, predicted = torch.max(outputs.data, 1)\n","    return classes[predicted.item()]\n","\n","# Streamlit app\n","st.title(\"Image Classification with CIFAR-10\")\n","st.write(\"Upload an image to classify\")\n","\n","uploaded_file = st.file_uploader(\"Choose an image...\", type=[\"jpg\", \"jpeg\", \"png\"])\n","if uploaded_file is not None:\n","    image = Image.open(uploaded_file)\n","    st.image(image, caption='Uploaded Image.', use_column_width=True)\n","    st.write(\"\")\n","    st.write(\"Classifying...\")\n","    label = predict(image)\n","    st.write(f\"The uploaded image is classified as: {label}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2w3IXShtRIXC","executionInfo":{"status":"ok","timestamp":1720172457485,"user_tz":-330,"elapsed":725,"user":{"displayName":"Jaswanth Pederedla","userId":"06036392412146825553"}},"outputId":"6b2d0e16-9bd7-4b57-bd38-72d46d4165f2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting app.py\n"]}]},{"cell_type":"markdown","metadata":{"id":"FytH31fff8_G"},"source":["## **WEB APP RELATED**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n53RoMcQgA84"},"outputs":[],"source":["# save\n","torch.save(model.state_dict(), 'cifar10_model.pth')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11893,"status":"ok","timestamp":1720165234778,"user":{"displayName":"Jaswanth Pederedla","userId":"06036392412146825553"},"user_tz":-330},"id":"u-UDQnDZlgiV","outputId":"d96fee52-7f0b-4712-f9d9-63a72f03ec0f"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.0/83.0 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["!pip install streamlit -q"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1720165234778,"user":{"displayName":"Jaswanth Pederedla","userId":"06036392412146825553"},"user_tz":-330},"id":"zlYCLfC2AuRh","outputId":"d655f633-cee6-49be-f105-8fb35779ae9e"},"outputs":[{"name":"stdout","output_type":"stream","text":["35.231.220.25\n"]}],"source":["!wget -q -O - ipv4.icanhazip.com"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6IrFkM0BmK31","executionInfo":{"status":"ok","timestamp":1720172661196,"user_tz":-330,"elapsed":192228,"user":{"displayName":"Jaswanth Pederedla","userId":"06036392412146825553"}},"outputId":"788562eb-3471-47d5-b3c4-32fbe41e041d"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K\u001b[?25hnpx: installed 22 in 3.618s\n","your url is: https://sad-bottles-shine.loca.lt\n","^C\n"]}],"source":["!streamlit run app.py &>/dev/null& npx localtunnel --port 8501"]}],"metadata":{"colab":{"provenance":[{"file_id":"1xvryFoZSkguA8NYQkVniHHkfPBCt4Thj","timestamp":1720172702925}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}